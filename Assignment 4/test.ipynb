{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.0 64-bit",
   "display_name": "Python 3.7.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dddbc276755de026ef59667a60cae8244bc070c6d03129960631c9bd95dbf04d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle_swarm_optimization(object):\n",
    "    def __init__(self, hiddenSize, inputSize, outputSize):\n",
    "        # initiate layers\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "\n",
    "        lenght_of_position = self.inputSize + self.hiddenSize + self.outputSize\n",
    "        layers = [self.inputSize] + [self.hiddenSize] + [self.outputSize]\n",
    "\n",
    "        # initiate positions\n",
    "        positions = []\n",
    "        positions_f = []\n",
    "        for i in range(len(layers)-1):\n",
    "            p = np.random.rand(layers[i], layers[i+1])\n",
    "            positions_f = np.concatenate((positions_f,p.flatten()), axis=None)\n",
    "            positions.append(p)\n",
    "        self.positions = positions\n",
    "        self.positions_fallten = positions_f\n",
    "\n",
    "        velocitys = []\n",
    "        for i in range(len(layers) - 1): \n",
    "            v = np.random.rand(layers[i+1])\n",
    "            velocitys.append(v)\n",
    "        self.velocitys = velocitys\n",
    "\n",
    "        p_best = []\n",
    "        for i in range(len(layers) - 1): \n",
    "            p_b = np.zeros(layers[i+1])\n",
    "            p_best.append(p_b)\n",
    "        self.p_best = p_best\n",
    "        \n",
    "\n",
    "    def update_velocity(self,p1,p2):\n",
    "\n",
    "    def fitness_function(self)\n",
    "\n",
    "    def _mae(self, target, output):\n",
    "        return np.average(abs(target - output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readfile(file):\n",
    "\n",
    "    # ----- Clean NaN Values -----\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.fillna(method = 'ffill')\n",
    "\n",
    "    # ----- Create Features -----\n",
    "    X = df[['PT08.S1(CO)','PT08.S2(NMHC)','PT08.S3(NOx)','PT08.S4(NO2)','PT08.S5(O3)','T','RH','AH']].copy(deep=False)\n",
    "    X.drop(X.tail(240).index,inplace=True)\n",
    "\n",
    "    # ----- Create Desired outputs -----\n",
    "    label = df[['C6H6(GT)']].copy(deep=False)\n",
    "\n",
    "    Y_10Day = label.iloc[240:,:].reset_index(drop=True)\n",
    "    Y_10Day.rename(columns={\"C6H6(GT)\":\"C6H6(GT)_10\"}, inplace = True)\n",
    "\n",
    "    Y_5Day = label.iloc[120:,:].reset_index(drop=True)\n",
    "    Y_5Day.drop(Y_5Day.tail(120).index,inplace=True)\n",
    "    Y_5Day.rename(columns={\"C6H6(GT)\":\"C6H6(GT)_5\"}, inplace = True)\n",
    "\n",
    "    Y = pd.concat([Y_5Day,Y_10Day], axis=1)\n",
    "\n",
    "    Input = X.to_numpy()\n",
    "    Output = Y.to_numpy()\n",
    "    return Input,Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[4870.85086147 5042.54046174]\n[4446.51534291 4660.83943651]\n"
     ]
    }
   ],
   "source": [
    "Input,Output = _readfile('data/AirQualityUCI.csv')\n",
    "\n",
    "PSO = Particle_swarm_optimization(4,8,2)\n",
    "\n",
    "PSO.train(Input[0:2],Output[0:2],1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}