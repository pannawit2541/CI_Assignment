{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.0 64-bit",
   "display_name": "Python 3.7.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dddbc276755de026ef59667a60cae8244bc070c6d03129960631c9bd95dbf04d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle_of_swarm(object):\n",
    "    def __init__(self, hiddenSize, inputSize, outputSize):\n",
    "        # initiate layers\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "\n",
    "        layers = [self.inputSize] + self.hiddenSize + [self.outputSize]\n",
    "\n",
    "        # initiate positions\n",
    "        positions = []\n",
    "        positions_f = []\n",
    "        for i in range(len(layers)-1):\n",
    "            p = np.random.rand(layers[i], layers[i+1])\n",
    "            positions_f = np.concatenate((positions_f,p.flatten()), axis=None)\n",
    "            positions.append(p)\n",
    "        self.positions = positions\n",
    "        self.positions_f = positions_f\n",
    "\n",
    "        velocitys = []\n",
    "        for i in range(len(layers) - 1): \n",
    "            v = np.random.rand(layers[i+1])\n",
    "            velocitys.append(v)\n",
    "        self.velocitys = velocitys\n",
    "\n",
    "\n",
    "        # for i in range(len(layers) - 1): \n",
    "        #     p_b = np.zeros(layers[i+1])\n",
    "        #     p_best.append(p_b)\n",
    "        # self.p_best = p_best\n",
    "\n",
    "    def feedForward(self, X):\n",
    "        Output_node = X\n",
    "        for i, p in enumerate(self.positions):\n",
    "            Output_node = np.dot(Output_node, p)\n",
    "\n",
    "        return Output_node\n",
    "\n",
    "    def object_funct(self,X,Y):\n",
    "        \n",
    "        sum_err = 0\n",
    "\n",
    "        for j,input in enumerate(X):\n",
    "\n",
    "            target = Y[j]\n",
    "            output = self.feedForward(input)\n",
    "\n",
    "            sum_err += self._mae(target,output)\n",
    "\n",
    "        self.pbest = (1/(sum_err+1))\n",
    "        return self.pbest\n",
    "\n",
    "    def _mae(self, target, output):\n",
    "        return np.average(abs(target - output))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Global_Best_Swarm(object):\n",
    "#     def __init__(self, Praticle):\n",
    "#         self.Praticle = Praticle\n",
    "\n",
    "#     def feedForward(self, X):\n",
    "#         output_node = X\n",
    "\n",
    "#         for i, p in enumerate(self.Praticle.positions):\n",
    "\n",
    "#             output_node = np.dot(output_node, p)\n",
    "\n",
    "#         return output_node  \n",
    "\n",
    "#     def objec_funct(self,X,Y,epoch):\n",
    "#         self.feedForward(X)\n",
    "\n",
    "#     def _mae(self, target, output):\n",
    "#         return np.average(abs(target - output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readfile(file):\n",
    "\n",
    "    # ----- Clean NaN Values -----\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.fillna(method = 'ffill')\n",
    "\n",
    "    # ----- Create Features -----\n",
    "    X = df[['PT08.S1(CO)','PT08.S2(NMHC)','PT08.S3(NOx)','PT08.S4(NO2)','PT08.S5(O3)','T','RH','AH']].copy(deep=False)\n",
    "    X.drop(X.tail(240).index,inplace=True)\n",
    "\n",
    "    # ----- Create Desired outputs -----\n",
    "    label = df[['C6H6(GT)']].copy(deep=False)\n",
    "\n",
    "    Y_10Day = label.iloc[240:,:].reset_index(drop=True)\n",
    "    Y_10Day.rename(columns={\"C6H6(GT)\":\"C6H6(GT)_10\"}, inplace = True)\n",
    "\n",
    "    Y_5Day = label.iloc[120:,:].reset_index(drop=True)\n",
    "    Y_5Day.drop(Y_5Day.tail(120).index,inplace=True)\n",
    "    Y_5Day.rename(columns={\"C6H6(GT)\":\"C6H6(GT)_5\"}, inplace = True)\n",
    "\n",
    "    Y = pd.concat([Y_5Day,Y_10Day], axis=1)\n",
    "\n",
    "    Input = X.to_numpy()\n",
    "    Output = Y.to_numpy()\n",
    "    return Input,Output\n",
    "\n",
    "Input,Output = _readfile('data/AirQualityUCI.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "particles = []\n",
    "p_bests = []\n",
    "num_of_particle = 10\n",
    "\n",
    "for i in range(0,num_of_particle):\n",
    "    par = Particle_of_swarm([4],8,2)\n",
    "    par.object_funct(Input,Output)\n",
    "    p_bests.append(par.pbest)\n",
    "    particles.append(par)\n",
    "\n",
    "g_best = max(p_bests)\n",
    "\n",
    "# for i in rang(0,num_of_particle):\n",
    "#     if particles[i].pbest < p_bests[i]:\n",
    "#         p_bests[i] = particles[i].pbest\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}